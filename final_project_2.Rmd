---
title: "p8130_final_project_2"
output: pdf_document
date: "2024-12-19"
---

# Project 2: Breast cancer survival prediction

```{r, include=FALSE}
library(tidyverse)
library(knitr)
library(car) 
library(e1071)
library(glmnet)
```

## Data exploration

### Descriptive table with summary statistics

```{r}
data <- read.csv("Project_2_data.csv")
head(data,10)

numerical_summary <- data %>%
  select_if(is.numeric) %>%
  summarise_all(list(
    count = ~sum(!is.na(.)),
    mean = mean,
    std = sd,
    min = min,
    median = median,
    max = max
  )) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value") %>%
  separate(Variable, into = c("Variable", "Statistic"), sep = "_")

formatted_summary <- numerical_summary %>%
  pivot_wider(names_from = Statistic, values_from = Value)

kable(formatted_summary, col.names = c("Variable", "Count", "Mean", "Std", "Min", "Median", "Max"), caption = "Numerical Variables Summary Statistics")
```

```{r}
categorical_vars <- data %>% select_if(is.character)

category_summary <- categorical_vars %>%
  gather(Variable, Category) %>%
  group_by(Variable, Category) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = round((Count / sum(Count)) * 100, 2)) %>%
  arrange(Variable, desc(Count))

formatted_summary <- category_summary %>%
  group_by(Variable) %>%
  mutate(Variable = ifelse(row_number() == 1, Variable, ""))

kable(formatted_summary, col.names = c("Variable", "Category", "Count", "Percentage (%)"), caption = "Category Distribution of Categorical Variables")
```

### Explore the Distribution of the Outcome (Status: Dead / Alive)
```{r}
status_distribution <- data %>%
  group_by(Status) %>%
  summarise(Count = n()) %>%
  mutate(Proportion = Count / sum(Count))

kable(status_distribution, col.names = c("Status", "Count", "Proportion"), caption = "Distribution of Survival Status (Dead/Alive)")

ggplot(data, aes(x = Status, fill = Status)) +
  geom_bar() +
  labs(title = "Distribution of Survival Status", x = "Status", y = "Count") +
  theme_minimal() +
  scale_fill_manual(values = c("lightblue", "pink"))
```

For logistic regression, the binary outcome variable (Status: Dead/Alive) does not require transformation, as logistic regression inherently models binary outcomes.

### Transformation
```{r}
# Identify numerical variables
numerical_vars <- data %>%
  select_if(is.numeric) %>%
  select(-`Survival.Months`)

# Display the list of numerical variables
names(numerical_vars)
# Convert Status to a binary numeric variable
data$Status <- ifelse(data$Status == "Dead", 1, 0)

# Scatterplots for each numerical variable against the logit
logit <- function(p) log(p / (1 - p))  # Logit function

numerical_vars %>%
  names() %>%
  map(~ ggplot(data, aes(x = .data[[.x]], y = Status)) +
        stat_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE, color = "blue") +
        geom_point(alpha = 0.5) +
        labs(title = paste("Relationship Between", .x, "and Logit of Status"), 
             x = .x, 
             y = "Logit(Status)") +
        theme_minimal())

# Calculate skewness for numerical variables
numerical_skewness <- numerical_vars %>%
  map_df(~ tibble(Variable = deparse(substitute(.)),
                  Skewness = skewness(., na.rm = TRUE)))

# Correct the Variable column
numerical_skewness <- tibble(
  Variable = colnames(numerical_vars),
  Skewness = sapply(numerical_vars, skewness, na.rm = TRUE)
)

# Display the skewness table
kable(numerical_skewness, col.names = c("Variable", "Skewness"), caption = "Skewness of Numerical Variables")
```

After our initial detection, we found out that: 

* Reginol.Node.Positive variable show slightly nonlinear with the logit of Status, it need transformation.

* The skewness analysis reveals that Age (-0.22) has a roughly symmetric distribution, requiring no transformation. Tumor Size (1.74) shows moderate right skewness, suggesting a potential log transformation to normalize the distribution, though it may not be strictly necessary. Regional Node Examined (0.83) has mild positive skewness and can likely be retained in its current form unless further diagnostics indicate otherwise. Reginol Node Positive (2.70), with significant right skewness, would benefit from a log transformation to reduce skewness and stabilize its relationship with the logit in the logistic regression model. These adjustments ensure numerical variables are well-prepared for regression analysis.

Base on the analysis above, try to make log transformation on Reginol Node Positive & Tumor Size.

```{r}
data <- data %>%
  mutate(
    Log_Reginol_Node_Positive = log1p(`Reginol.Node.Positive`),
    Log_Tumor_Size = log1p(`Tumor.Size`)
  )
transformed_skewness <- data %>%
  select(Log_Reginol_Node_Positive, Log_Tumor_Size) %>%
  summarise_all(~ skewness(.))

# Combine with variable names
transformed_skewness_table <- tibble(
  Variable = c("Log_Reginol_Node_Positive", "Log_Tumor_Size"),
  Skewness = as.numeric(transformed_skewness)
)

# Display the updated skewness table
kable(transformed_skewness_table, col.names = c("Variable", "Skewness"), caption = "Skewness of Transformed Variables")

## Plots for Transformed Variables Against Logit of Status
logit <- function(p) log(p / (1 - p))  # Logit function

# Plot for Log_Reginol_Node_Positive
ggplot(data, aes(x = Log_Reginol_Node_Positive, y = Status)) +
  stat_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE, color = "blue") +
  geom_point(alpha = 0.5) +
  labs(title = "Relationship Between Log_Reginol_Node_Positive and Logit of Status", x = "Log_Reginol_Node_Positive", y = "Logit(Status)") +
  theme_minimal()

# Plot for Log_Tumor_Size
ggplot(data, aes(x = Log_Tumor_Size, y = Status)) +
  stat_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE, color = "blue") +
  geom_point(alpha = 0.5) +
  labs(title = "Relationship Between Log_Tumor_Size and Logit of Status", x = "Log_Tumor_Size", y = "Logit(Status)") +
  theme_minimal()
```

Comments:

* For Log_Reginol_Node_Positive, the skewness improved from 2.70 to 0.99, indicating a significant reduction in skewness. While still slightly positively skewed, the value is now within an acceptable range for modeling.

* For Log_Tumor_Size, the skewness reduced from 1.74 to -0.09, making it almost symmetric. This transformation effectively normalized the variable.

* For Log_Reginol_Node_Positive, the log transformation on Reginol.Node.Positive likely improved its relationship with the logit

* For Log_Tumor_Size, the curvature is still present after the transformation, and the linearity with the logit has not significantly improved. 

As a result, we should definitely conduct a log transformation on Log_Reginol_Node_Positive, we are not sure on Log_Tumor_Size, we can evaluate it in model selection.

```{r}
data=data |>
  select(-`Reginol.Node.Positive`, -`Tumor.Size`)
```

```{r}
# check for multicollinearity among numeric variables
selected_vars <- c("Age", "Log_Reginol_Node_Positive", "Log_Tumor_Size","Regional.Node.Examined")

subset_data <- data[, selected_vars]

if (all(sapply(subset_data, is.numeric))) {
  correlation_matrix <- cor(subset_data, use = "pairwise.complete.obs")
  print(correlation_matrix)
}
```

None of the correlation coefficients between numeric variables exceed 0.5, indicating that there is no strong linear relationship between each pair of numeric variables.

```{r}
# Checking for highly consistent category variables

category1 <- "differentiate"
category2 <- "Grade"

contingency_table <- table(data[[category1]], data[[category2]])
print(contingency_table)
```

We discover that complete linear dependency exist among Grade and differentiate, so we can only include one of them in the prediction model, so differentiate is excluded.

Finally, we need to change all the catagorical variables to dummy variables:
```{r}
categorical_vars <- data %>%
  select_if(is.character) %>%
  names()

data_final <- data %>%
  mutate(across(all_of(categorical_vars), ~ as.factor(.))) %>%  
  model.matrix(~ . - 1, data = .) %>%  
  as.data.frame() 

head(data_final,10)
```

Lasso + model:
```{r}
x <- model.matrix(Status ~ ., data = data_final)[, -1]  # 去掉截距列
y <- data_final$Status

# 使用 Lasso 进行变量筛选
lasso_cv <- cv.glmnet(x, y, family = "binomial", alpha = 1)

# 获取最佳正则化参数 lambda
best_lambda <- lasso_cv$lambda.min
print(paste("Optimal lambda:", best_lambda))

# 使用最佳 lambda 拟合 Lasso 模型
lasso_model <- glmnet(x, y, family = "binomial", alpha = 1, lambda = best_lambda)

# 提取 Lasso 模型的系数
lasso_coefficients <- coef(lasso_model)

# 转换为标准矩阵格式
lasso_coefficients_matrix <- as.matrix(lasso_coefficients)

# 提取非零系数对应的变量名（去掉截距项）
selected_vars <- rownames(lasso_coefficients_matrix)[lasso_coefficients_matrix != 0][-1]

# 输出筛选出的变量
print("Selected variables:")
print(selected_vars)

# 构建最终的逻辑回归模型
final_formula <- as.formula(paste("Status ~", paste(selected_vars, collapse = " + ")))
final_model <- glm(final_formula, data = data_final, family = "binomial")

# 输出最终模型的摘要
summary(final_model)

```

```{r}
############################################################
# Model Diagnostics (No Interaction Yet)
############################################################
final_model <- glm(final_formula, data = data_final, family = "binomial", x=TRUE, y=TRUE)

# 1. VIF
vif_values <- vif(final_model)
cat("VIF Values:\n")
print(vif_values)

# Get predictions
pred_prob <- predict(final_model, type = "response")

# Check lengths
if(length(pred_prob) != length(data_final$Status)){
  stop("pred_prob and Status differ in length!")
}

# Check for NAs
if(any(is.na(data_final$Status)) || any(is.na(pred_prob))){
  stop("NAs found in Status or pred_prob!")
}

# 2. Hosmer-Lemeshow Test
hl_test <- tryCatch({
  hoslem.test(data_final$Status, pred_prob, g=5)
})
cat("Hosmer-Lemeshow Test:\n")
print(hl_test)

# 3. Influential Observations
influence_measures_res <- influence.measures(final_model)
summary(influence_measures_res)

# 4. Linearity Check (e.g., Log_Tumor_Size)
if("Log_Tumor_Size" %in% selected_vars) {
  crPlots(final_model, terms = "Log_Tumor_Size")
}

# 5. ROC and AUC
roc_obj <- roc(data_final$Status, pred_prob)
auc_value <- auc(roc_obj)
cat("Overall AUC:", auc_value, "\n")
plot(roc_obj, main=paste("ROC Curve, AUC =", round(auc_value,3)))


```

```{r}
# Histogram of predicted probabilities
ggplot(data_final, aes(x = pred_prob)) +
  geom_histogram(binwidth = 0.05, fill = "steelblue", color = "black") +
  labs(title = "Distribution of Predicted Probabilities", x = "Predicted Probability", y = "Frequency") +
  theme_minimal()

```

```{r}
# Check if both variables are selected
if(all(c("RaceBlack", "Log_Tumor_Size") %in% selected_vars)) {
  
  # Update formula to include interaction
  final_formula_inter <- update(final_formula, . ~ . + RaceBlack:Log_Tumor_Size)
  
  # Fit the Interaction Model
  final_model_inter <- glm(final_formula_inter, data = data_final, family = "binomial")
  
  # Check for Aliasing
  alias_results_inter <- alias(final_model_inter)
  print(alias_results_inter)
  
  # If Aliasing Exists, Remove Problematic Terms
  problem_vars_inter <- rownames(alias_results_inter$Complete)[rowSums(alias_results_inter$Complete) > 0]
  if(length(problem_vars_inter) > 0) {
    selected_vars <- setdiff(selected_vars, problem_vars_inter)
    final_formula_inter <- as.formula(paste("Status ~", paste(selected_vars, collapse = " + "), "+ RaceBlack:Log_Tumor_Size"))
    final_model_inter <- glm(final_formula_inter, data = data_final, family = "binomial")
  }
  
  # Summary of Interaction Model
  summary(final_model_inter)
  
  # Re-run Diagnostics for Interaction Model
  
  # VIF
  vif_values_inter <- vif(final_model_inter)
  kable(as.data.frame(vif_values_inter), 
        col.names = c("VIF"), 
        caption = "VIF Values for Interaction Model Predictors")
  
  # Predictions
  pred_prob_inter <- predict(final_model_inter, type = "response")
  
  # Hosmer-Lemeshow Test for Interaction Model
  hl_test_inter <- tryCatch({
    ResourceSelection::hoslem.test(data_final$Status, pred_prob_inter, g = 5)
  }, error = function(e) {
    message("Hosmer-Lemeshow test failed with g=5 for interaction model. Trying g=3...")
    ResourceSelection::hoslem.test(data_final$Status, pred_prob_inter, g = 3)
  })
  
  cat("Hosmer-Lemeshow Test (Interaction Model):\n")
  print(hl_test_inter)
  
  # Manual Hosmer-Lemeshow Test for Interaction Model
  if(inherits(hl_test_inter, "try-error")) {
    cat("Implementing Manual Hosmer-Lemeshow Test for Interaction Model...\n")
    
    # Create Deciles
    data_final <- data_final %>%
      mutate(decile_inter = ntile(pred_prob_inter, 10))
    
    # Calculate Observed and Expected Counts per Decile
    hl_manual_inter <- data_final %>%
      group_by(decile_inter) %>%
      summarise(
        observed = sum(Status),
        expected = sum(pred_prob_inter),
        n = n()
      ) %>%
      mutate(
        variance = expected * (1 - mean(pred_prob_inter)),
        chi_square = (observed - expected)^2 / variance
      )
    
    # Total Chi-Square Statistic
    chi_square_total_inter <- sum(hl_manual_inter$chi_square)
    degrees_freedom_inter <- 10 - 2  # g - number of parameters
    
    # P-Value
    p_value_hl_manual_inter <- 1 - pchisq(chi_square_total_inter, df = degrees_freedom_inter)
    
    # Display Results
    kable(hl_manual_inter, 
          col.names = c("Decile", "Observed", "Expected", "n", "Variance", "Chi-Square"),
          caption = "Manual Hosmer-Lemeshow Test Table for Interaction Model")
    
    cat("Manual Hosmer-Lemeshow Test (Interaction Model):\n")
    cat("Chi-Square:", round(chi_square_total_inter, 2), 
        "Degrees of Freedom:", degrees_freedom_inter, 
        "P-Value:", round(p_value_hl_manual_inter, 4), "\n")
  }
  
  # Influential Observations for Interaction Model
  influence_measures_res_inter <- influence.measures(final_model_inter)
  summary(influence_measures_res_inter)
  
  # Linearity Check
  if("Log_Tumor_Size" %in% selected_vars) {
    crPlots(final_model_inter, terms = "Log_Tumor_Size")
  }
  
  # ROC and AUC for Interaction Model
  roc_obj_inter <- roc(data_final$Status, pred_prob_inter)
  auc_value_inter <- auc(roc_obj_inter)
  cat("Overall AUC (Interaction Model):", auc_value_inter, "\n")
  
  # Plot ROC Curve
  plot(roc_obj_inter, main = paste("ROC Curve (Interaction Model), AUC =", round(auc_value_inter, 3)))
  
  # Compare AICs
  cat("AIC without Interaction:", AIC(final_model), "\n")
  cat("AIC with Interaction:", AIC(final_model_inter), "\n")
  
  # Likelihood Ratio Test
  anova(final_model, final_model_inter, test = "Chisq")
  
  # Update model_to_interpret for Interpretation
  model_to_interpret <- final_model_inter
} else {
  model_to_interpret <- final_model
}

```



